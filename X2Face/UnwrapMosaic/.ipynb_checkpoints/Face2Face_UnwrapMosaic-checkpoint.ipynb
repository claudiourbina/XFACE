{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This jupyter notebook contains demo code for:\n",
    "- loading a model and using it to \n",
    "- drive one or more source frames with a set of driving frames\n",
    "- modifying the embedded face to perform video editing for both the dragon tattoo and Harry Potter scar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'matplotlib' has no attribute 'artist'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-0233b0cc175e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#%matplotlib inline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m   1109\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatch_warnings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1110\u001b[0m     \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMatplotlibDeprecationWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1111\u001b[1;33m     \u001b[0mrcParamsOrig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRcParams\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1112\u001b[0m     rcParamsDefault = RcParams([(key, default) for key, (default, converter) in\n\u001b[0;32m   1113\u001b[0m                                 \u001b[0mdefaultParams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    889\u001b[0m             \u001b[0mval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mval\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mrcsetup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_auto_backend_sentinel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 891\u001b[1;33m                 \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m                 \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mswitch_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrcsetup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_auto_backend_sentinel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcycler\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcycler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolorbar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrcsetup\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstyle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\matplotlib\\colorbar.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmpl\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0martist\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmartist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcbook\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollections\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'matplotlib' has no attribute 'artist'"
     ]
    }
   ],
   "source": [
    "#%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch.autograd import Variable\n",
    "from UnwrappedFace import UnwrappedFaceWeightedAverage, UnwrappedFaceWeightedAveragePose\n",
    "import torchvision\n",
    "from torchvision.transforms import ToTensor, Compose, Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_batch(source_images, pose_images, requires_grad=False, volatile=False):\n",
    "    return model(pose_images, *source_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_MODEL = '/scratch/shared/slow/ow/eccv/2018/release_models/' # Change to your path\n",
    "state_dict = torch.load(BASE_MODEL + 'x2face_model.pth')\n",
    "\n",
    "model = UnwrappedFaceWeightedAverage(output_num_channels=2, input_num_channels=3, inner_nc=128)\n",
    "model.load_state_dict(state_dict['state_dict'])\n",
    "model = model.cuda()\n",
    "\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code for driving with another set of frames**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_path = './examples/Taylor_Swift/1.6/nuBaabkzzzI/'\n",
    "source_path = './examples/Taylor_Swift/1.6/vBgiDYBCuxY/'\n",
    "\n",
    "driver_imgs = [driver_path + d for d in sorted(os.listdir(driver_path))][0:8] # 8 driving frames\n",
    "source_imgs  = [source_path + d for d in sorted(os.listdir(source_path))][0:3] # 3 source frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(file_path):\n",
    "    img = Image.open(file_path)\n",
    "    transform = Compose([Scale((256,256)), ToTensor()])\n",
    "    return Variable(transform(img)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Driving the source image with the driving sequence\n",
    "source_images = []\n",
    "for img in source_imgs:\n",
    "    source_images.append(load_img(img).unsqueeze(0).repeat(len(driver_imgs), 1, 1, 1))\n",
    "    \n",
    "driver_images = None\n",
    "for img in driver_imgs:\n",
    "    if driver_images is None:\n",
    "        driver_images = load_img(img).unsqueeze(0)\n",
    "    else:\n",
    "        driver_images = torch.cat((driver_images, load_img(img).unsqueeze(0)), 0)\n",
    "\n",
    "# Run the model for each\n",
    "result = run_batch(source_images, driver_images)\n",
    "result = result.clamp(min=0, max=1)\n",
    "img = torchvision.utils.make_grid(result.cpu().data)\n",
    "    \n",
    "# Visualise the results\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 24.\n",
    "fig_size[1] = 24.\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "plt.axis('off')\n",
    "\n",
    "result_images = img.permute(1,2,0).numpy()\n",
    "driving_images = torchvision.utils.make_grid(driver_images.cpu().data).permute(1,2,0).numpy()\n",
    "print(\"The results is: \")\n",
    "plt.imshow(np.vstack((result_images, driving_images)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code for using the dragon tattoo to modify the unwrapped mosaic**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the dragon tattoo\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 1.\n",
    "fig_size[1] = 1.\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "\n",
    "tattoo = Image.open('./tattoos/dragon_tattoo.png')\n",
    "tattoo = tattoo.resize((30,30), Image.BILINEAR).rotate(45).convert('RGBA')\n",
    "\n",
    "b, g, r, a = tattoo.split()\n",
    "tattoo = Image.merge(\"RGBA\", (g, b, r, a))\n",
    "tattoo_flipped = tattoo.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "\n",
    "tattoo = np.array(tattoo) / 256.\n",
    "tattoo[:,:,[1,2]] = 1\n",
    "tattoo_flipped = np.array(tattoo_flipped) / 256.\n",
    "tattoo_flipped[:,:,[1,2]] = 1\n",
    "print(\"The tattoo: \")\n",
    "plt.imshow(tattoo)\n",
    "\n",
    "# Add a flipped version to make a moustache\n",
    "tattoo = torch.Tensor(tattoo)\n",
    "tattoo_flipped = torch.Tensor(tattoo_flipped)\n",
    "tattoo = tattoo.permute(2,0,1)\n",
    "tattoo_flipped = tattoo_flipped.permute(2,0,1)\n",
    "\n",
    "# Changes the colour\n",
    "alpha = tattoo[3:4,:,:].cuda()\n",
    "tattoo = tattoo[0:3,:,:].cuda()\n",
    "alpha_flipped = tattoo_flipped[3:4,:,:].cuda()\n",
    "tattoo_flipped = tattoo_flipped[0:3,:,:].cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reload driving / source frames\n",
    "driver_path = './examples/Taylor_Swift/1.6/nuBaabkzzzI/'\n",
    "source_path = './examples/Taylor_Swift/1.6/nuBaabkzzzI/'\n",
    "\n",
    "driver_imgs = [driver_path + d for d in sorted(os.listdir(driver_path))][0:8] # 8 driving frames\n",
    "source_imgs  = [source_path + d for d in sorted(os.listdir(source_path))][0:1] # 1 source frames\n",
    "\n",
    "source_images = []\n",
    "for img in source_imgs:\n",
    "    source_images.append(load_img(img).unsqueeze(0))\n",
    "    \n",
    "driver_images = None\n",
    "for img in driver_imgs:\n",
    "    if driver_images is None:\n",
    "        driver_images = load_img(img).unsqueeze(0)\n",
    "    else:\n",
    "        driver_images = torch.cat((driver_images, load_img(img).unsqueeze(0)), 0)\n",
    "\n",
    "        \n",
    "# Modify the face with the given tattoo \n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 4.\n",
    "fig_size[1] = 4.\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "\n",
    "# Get the unwrapped face\n",
    "sampler = model.pix2pixUnwrapped(*source_images)[0][:,0:2,:,:]\n",
    "xs = np.linspace(-1,1,256)\n",
    "xs = np.meshgrid(xs, xs)  \n",
    "xs = np.stack(xs, 2) \n",
    "xs = torch.Tensor(xs).unsqueeze(0).repeat(1, 1,1,1).cuda()\n",
    "sampler = nn.Tanh()(sampler).permute(0,2,3,1) + Variable(xs, requires_grad=False)\n",
    "\n",
    "# Visualise unwrapped face with tattoo\n",
    "result = nn.functional.grid_sample(source_images[0],  sampler).squeeze().cpu()\n",
    "alpha = alpha.cpu()\n",
    "tattoo = tattoo.cpu()\n",
    "to_copy = tattoo * alpha.float() + (1 - alpha.float()) * result[:,125:155,90:120].data.cpu()\n",
    "to_copy = Variable(to_copy).cuda()\n",
    "result[:,125:155,90:120] = to_copy\n",
    "\n",
    "alpha_flipped = alpha_flipped.cpu()\n",
    "tattoo_flipped = tattoo_flipped.cpu()\n",
    "to_copy = tattoo_flipped * alpha_flipped.float() + (1 - alpha_flipped.float()) * result[:,125:155,150:180].data.cpu()\n",
    "to_copy = Variable(to_copy).cuda()\n",
    "result[:,125:155,150:180] = to_copy\n",
    "plt.imshow(result.data.squeeze().cpu().permute(1,2,0).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the model for each\n",
    "output_sampler = model.pix2pixSampler(driver_images)[0]\n",
    "output_sampler = nn.Tanh()(output_sampler).permute(0,2,3,1) + Variable(xs, requires_grad=False)\n",
    "result = nn.functional.grid_sample(result.unsqueeze(0).repeat(output_sampler.size(0), 1, 1, 1), \n",
    "                                       output_sampler.cpu()).squeeze()\n",
    "    \n",
    "result = result.clamp(min=0, max=1)\n",
    "img = torchvision.utils.make_grid(result.cpu().data)\n",
    "    \n",
    "# Visualise the results\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 24.\n",
    "fig_size[1] = 24.\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "plt.axis('off')\n",
    "\n",
    "result_images = img.permute(1,2,0).numpy()\n",
    "driving_images = torchvision.utils.make_grid(driver_images.cpu().data).permute(1,2,0).numpy()\n",
    "print(\"The unwrapped mosaic driven with the given face is: \")\n",
    "plt.imshow(np.vstack((result_images, driving_images)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code for using the Harry Potter scar to modify the unwrapped mosaic**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generat the tattoo for the hp scar\n",
    "index = 7\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 1.\n",
    "fig_size[1] = 1.\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "from PIL import Image\n",
    "tattoo = Image.open('./tattoos/hp_scar_2.png')\n",
    "tattoo = tattoo.resize((30,30), Image.BILINEAR).rotate(45).convert('RGBA')\n",
    "b, g, r, a = tattoo.split()\n",
    "tattoo = Image.merge(\"RGBA\", (g, b, r, a))\n",
    "\n",
    "tattoo = np.array(tattoo) / 256.\n",
    "tattoo[:,:,[0,1]] = 1\n",
    "tattoo = torch.Tensor(tattoo)\n",
    "tattoo = tattoo.permute(2,0,1)\n",
    "alpha = tattoo[2,:,:] < 0.9\n",
    "tattoo = tattoo[0:3,:,:]\n",
    "\n",
    "# Graph the result concatenated with the original frame across a sequence of frames : does the expression change?\n",
    "# Match the \n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 4.\n",
    "fig_size[1] = 4.\n",
    "plt.rcParams[\"figure.figsize\"] = (5,5)\n",
    "\n",
    "# Get the unwrapped face\n",
    "sampler = model.pix2pixUnwrapped(*source_images)[0][:,0:2,:,:]\n",
    "xs = np.linspace(-1,1,256)\n",
    "xs = np.meshgrid(xs, xs)  \n",
    "xs = np.stack(xs, 2) \n",
    "xs = torch.Tensor(xs).unsqueeze(0).repeat(1, 1,1,1).cuda()\n",
    "sampler = nn.Tanh()(sampler).permute(0,2,3,1) + Variable(xs, requires_grad=False)\n",
    "result = nn.functional.grid_sample(source_images[0],  sampler).squeeze()\n",
    "\n",
    "alpha = alpha.float().clamp(max=1.0) # modify to make more/less realistic\n",
    "to_copy = tattoo * alpha.float() + (1 - alpha.float()) * result[:,45:75,120:150].data.cpu()\n",
    "to_copy = Variable(to_copy).cuda()\n",
    "result[:,45:75,120:150] = to_copy\n",
    "plt.imshow(result.data.squeeze().cpu().permute(1,2,0).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the model for each\n",
    "output_sampler = model.pix2pixSampler(driver_images)[0]\n",
    "output_sampler = nn.Tanh()(output_sampler).permute(0,2,3,1) + Variable(xs, requires_grad=False)\n",
    "result = nn.functional.grid_sample(result.unsqueeze(0).repeat(output_sampler.size(0), 1, 1, 1).cpu(), \n",
    "                                       output_sampler.cpu()).squeeze()\n",
    "    \n",
    "result = result.clamp(min=0, max=1)\n",
    "img = torchvision.utils.make_grid(result.cpu().data)\n",
    "    \n",
    "# Visualise the results\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 24.\n",
    "fig_size[1] = 24.\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "plt.axis('off')\n",
    "\n",
    "result_images = img.permute(1,2,0).numpy()\n",
    "driving_images = torchvision.utils.make_grid(driver_images.cpu().data).permute(1,2,0).numpy()\n",
    "print(\"The unwrapped mosaic driven with the given face is: \")\n",
    "plt.imshow(np.vstack((result_images, driving_images)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
